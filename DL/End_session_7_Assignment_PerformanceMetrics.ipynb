{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNx+cOAco4ydTB7CIpRO1WE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f0e725e883a647dbbbf59d4627ca149b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a0f9bb271c54664a6f90337020d2b57",
              "IPY_MODEL_95f3483ee0a147d8bc111ecd97b8d2ed",
              "IPY_MODEL_3ec578caa2c84af8a2dc7300ea1196fc"
            ],
            "layout": "IPY_MODEL_2060c34260224ed3a1792c4b54a19448"
          }
        },
        "9a0f9bb271c54664a6f90337020d2b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_413005c86f8e453c8156682cbb911e95",
            "placeholder": "​",
            "style": "IPY_MODEL_b036863994ac4aed87cbaf2ed9cbcc9d",
            "value": "  0%"
          }
        },
        "95f3483ee0a147d8bc111ecd97b8d2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49cc3d0ef4e34393a02497a49ff7f0cb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f7b85331af2404bb27e3e1e1420aac5",
            "value": 0
          }
        },
        "3ec578caa2c84af8a2dc7300ea1196fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0c203aa78ba4efe9d75cf674675f14f",
            "placeholder": "​",
            "style": "IPY_MODEL_3ee825b28dc9455ead847d70c742b5dd",
            "value": " 0/1 [00:00&lt;?, ?it/s]"
          }
        },
        "2060c34260224ed3a1792c4b54a19448": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "413005c86f8e453c8156682cbb911e95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b036863994ac4aed87cbaf2ed9cbcc9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49cc3d0ef4e34393a02497a49ff7f0cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f7b85331af2404bb27e3e1e1420aac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0c203aa78ba4efe9d75cf674675f14f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ee825b28dc9455ead847d70c742b5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "Tcz7bXHGz9Lb",
        "outputId": "c29b3acb-57be-4331-b5b4-d450356f10a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-27 11:37:33--  http://www.cs.cmu.edu/~ark/QA-data/data/Question_Answer_Dataset_v1.2.tar.gz\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8254496 (7.9M) [application/x-gzip]\n",
            "Saving to: ‘Question_Answer_Dataset_v1.2.tar.gz.6’\n",
            "\n",
            "Question_Answer_Dat 100%[===================>]   7.87M  4.31MB/s    in 1.8s    \n",
            "\n",
            "2023-04-27 11:37:35 (4.31 MB/s) - ‘Question_Answer_Dataset_v1.2.tar.gz.6’ saved [8254496/8254496]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./data/question_answer_pairs.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "# !pip install torch\n",
        "import torch\n",
        "import tarfile\n",
        "import torch.nn as nn\n",
        "import shutil\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "!wget http://www.cs.cmu.edu/~ark/QA-data/data/Question_Answer_Dataset_v1.2.tar.gz\n",
        "  \n",
        "file = tarfile.open('Question_Answer_Dataset_v1.2.tar.gz')  # open file\n",
        "file.extractall('./data') # extract files  \n",
        "file.close()# close file\n",
        "\n",
        "file_path = './data/question_answer_pairs.txt'\n",
        "shutil.move(\"./data/Question_Answer_Dataset_v1.2/S08/question_answer_pairs.txt\", file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "class Data:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "def readData(file_path):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('{}'.format(file_path), encoding='latin-1').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')[1:3]] for l in lines]\n",
        "    pairs = pairs[1:]\n",
        "\n",
        "    question_details = Data('question')  # CHECK\n",
        "    answer_details = Data('answer')  # CHECK\n",
        "\n",
        "    return question_details, answer_details, pairs\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH \n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "def prepareData(file_path):\n",
        "    question_details, answer_details, pairs = readData(file_path)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        question_details.addSentence(pair[0])\n",
        "        answer_details.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(question_details.name, question_details.n_words)\n",
        "    print(answer_details.name, answer_details.n_words)\n",
        "    return question_details, answer_details, pairs\n",
        "\n",
        "\n",
        "question_details, answer_details, pairs = prepareData(file_path)\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-fNavSQbJt2",
        "outputId": "6a20c55e-c983-4e41-be4d-8dbb1be78062"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 1715 sentence pairs\n",
            "Trimmed to 926 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "question 992\n",
            "answer 670\n",
            "['have kangaroos fared well since european settlement ?', 'yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (pairs)  # remove ? and . from end. After that, remove whitestapces from end\n",
        "\n",
        "answer_details.name, answer_details.n_words, question_details.name, question_details.n_words\n",
        "# (answer_details.word2index, answer_details.index2word, answer_details.word2count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2bT1qOwUefH",
        "outputId": "a4aeacf4-b883-4a1a-9303-f59633d12c41"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('answer', 670, 'question', 992)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(question_details, pair[0])\n",
        "    target_tensor = tensorFromSentence(answer_details, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "TN3q-9bVdJQL"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)  # this is SOS token\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = F.relu(output)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "YOpz62VWctJh"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert_score==0.3.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRnXXxZgYm03",
        "outputId": "82e256ea-1c05-41bf-e756-07df3d00396c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bert_score==0.3.4 in /usr/local/lib/python3.9/dist-packages (0.3.4)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from bert_score==0.3.4) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from bert_score==0.3.4) (3.7.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from bert_score==0.3.4) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from bert_score==0.3.4) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from bert_score==0.3.4) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.9/dist-packages (from bert_score==0.3.4) (4.65.0)\n",
            "Requirement already satisfied: transformers>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from bert_score==0.3.4) (4.28.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.1->bert_score==0.3.4) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.1->bert_score==0.3.4) (2.8.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->bert_score==0.3.4) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->bert_score==0.3.4) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->bert_score==0.3.4) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->bert_score==0.3.4) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->bert_score==0.3.4) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.0->bert_score==0.3.4) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.0.0->bert_score==0.3.4) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.0.0->bert_score==0.3.4) (3.25.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.2.0->bert_score==0.3.4) (0.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.2.0->bert_score==0.3.4) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.2.0->bert_score==0.3.4) (0.14.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.2.0->bert_score==0.3.4) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.2.0->bert_score==0.3.4) (2022.10.31)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert_score==0.3.4) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert_score==0.3.4) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert_score==0.3.4) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert_score==0.3.4) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert_score==0.3.4) (1.0.7)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert_score==0.3.4) (5.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert_score==0.3.4) (4.39.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->bert_score==0.3.4) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->bert_score==0.3.4) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->bert_score==0.3.4) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->bert_score==0.3.4) (3.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=2.2.0->bert_score==0.3.4) (2023.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->bert_score==0.3.4) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert_score==0.3.4) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.0.0->bert_score==0.3.4) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.0.0->bert_score==0.3.4) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.25\n",
        "import math\n",
        "from bert_score import score\n",
        "\n",
        "def unigram_precision(predicted_tensor, target_tensor):\n",
        "    predicted_tensor_flatten = torch.flatten(predicted_tensor)\n",
        "    predicted_tensor_frequencies = torch.bincount(predicted_tensor_flatten.type(torch.int64))\n",
        "    total_predicted_tensor_frequencies = torch.sum(predicted_tensor_frequencies)  # Denominator for unigram precision computation.\n",
        "\n",
        "    target_tensor_flatten = torch.flatten(target_tensor)\n",
        "    target_tensor_frequencies = torch.bincount(target_tensor_flatten.type(torch.int64))\n",
        "    # print(predicted_tensor_flatten, predicted_tensor_frequencies)  \n",
        "    # print(target_tensor_flatten, target_tensor_frequencies)\n",
        "    \n",
        "    len_pred = list(predicted_tensor_frequencies.shape)[0]\n",
        "    len_target = list(target_tensor_frequencies.shape)[0]\n",
        "    # make_len_equal_target_pred_by_appending_zeros\n",
        "    if len_pred > len_target:  # len of pred is more than len of actual\n",
        "        target_tensor_frequencies = nn.ConstantPad1d((0, len_pred - len_target), 0)(target_tensor_frequencies)\n",
        "    elif len_pred < len_target:\n",
        "        predicted_tensor_frequencies = nn.ConstantPad1d((0, len_target - len_pred), 0)(predicted_tensor_frequencies)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    min_pred_target_frequencies = torch.min(predicted_tensor_frequencies, target_tensor_frequencies)  # Clip count - keep min of pred and actual freq\n",
        "    # print(predicted_tensor_frequencies, target_tensor_frequencies, min_pred_target_frequencies, torch.sum(min_pred_target_frequencies), torch.sum(min_pred_target_frequencies).item())\n",
        "    total_min_pred_target_tensor_frequencies = torch.sum(min_pred_target_frequencies)  # Numerator for unigram precision computation.\n",
        "    # print('sid', total_min_pred_target_tensor_frequencies.item(), total_predicted_tensor_frequencies.item())\n",
        "    try:\n",
        "        unigram_precision_val = total_min_pred_target_tensor_frequencies.item() / total_predicted_tensor_frequencies.item()\n",
        "    except ZeroDivisionError:\n",
        "        unigram_precision_val = 0\n",
        "    # print('u prc val :', unigram_precision_val)\n",
        "    return unigram_precision_val\n",
        "\n",
        "def brevity_panelty(predicted_target_trimmed, target_tensor_trimmed):  # penalize machine output which is of lesser length than actual output\n",
        "    count_elements_in_predicted_target_trimmed = predicted_target_trimmed.numel()\n",
        "    count_elements_in_target_tensor_trimmed = target_tensor_trimmed.numel()\n",
        "    if int(count_elements_in_predicted_target_trimmed) < int(count_elements_in_target_tensor_trimmed):\n",
        "        # print(count_elements_in_target_tensor_trimmed, count_elements_in_predicted_target_trimmed)\n",
        "        try:\n",
        "            penalty = math.exp((1-(count_elements_in_target_tensor_trimmed/count_elements_in_predicted_target_trimmed)))\n",
        "        except ZeroDivisionError:\n",
        "            penalty = math.exp(1)\n",
        "        return penalty\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    prob_for_perplexity = []\n",
        "\n",
        "    if True:  # use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        predicted_target = torch.zeros(max_length, 1, device=device)  # evaluation\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            \n",
        "            prob_for_perplexity.append(topv.squeeze())\n",
        "\n",
        "            decoder_input_for_precision = topi.squeeze().detach()  # detach from history as input\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            predicted_target[di] = decoder_input_for_precision  # evaluation\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "        perplexity = math.exp((-1/target_length) * sum(prob_for_perplexity))  # Compute Perplexity\n",
        "\n",
        "        predicted_target_trimmed = predicted_target[predicted_target.sum(dim=1) != 0]  # remove unwanted rows at the end with 0 value.\n",
        "        predicted_target_trimmed = predicted_target_trimmed[predicted_target_trimmed[:, 0] !=1]  # remove last row in case it has EOS token\n",
        "        row_exclude = target_tensor.shape[0]-1\n",
        "        target_tensor_trimmed = torch.cat((target_tensor[:row_exclude],target_tensor[row_exclude+1:]))  # remove EOS token from end\n",
        "\n",
        "        # Compute Bert Score between Predicted and Target Sent\n",
        "        # print(\"siddharth \", predicted_target_trimmed.shape, type(predicted_target_trimmed), predicted_target_trimmed)\n",
        "        decoded_words = []  # Predicted Sentence\n",
        "        decoded_sentence_list = []\n",
        "        for predicted_target_index in (predicted_target_trimmed.squeeze()).type('torch.IntTensor'):\n",
        "            decoded_words.append(answer_details.index2word[predicted_target_index.item()])\n",
        "        decoded_sentence = ' '.join(decoded_words)\n",
        "        decoded_sentence_list.append(decoded_sentence)\n",
        "        target_words = []\n",
        "        target_sentence_list = []\n",
        "        for target_tensor in (target_tensor_trimmed.squeeze()).type('torch.IntTensor'):\n",
        "            target_words.append(answer_details.index2word[target_tensor.item()])\n",
        "        target_sentence = ' '.join(target_words)\n",
        "        target_sentence_list.append(target_sentence)\n",
        "        BERT_P, BERT_R, BERT_F1 = score(decoded_sentence_list, target_sentence_list, lang=\"en\", verbose=True)\n",
        "\n",
        "        # Calculate unigram precision for predicted and target. Continue to compute penalty and BLEU score.\n",
        "        unigram_precision_value = unigram_precision(predicted_target_trimmed, target_tensor_trimmed)\n",
        "        modified_n_gram_precision = math.sqrt(unigram_precision_value)  # n is 2 - square root - since we are using unigram and bigrams.\n",
        "        brevity_panelty_val = brevity_panelty(predicted_target_trimmed, target_tensor_trimmed)\n",
        "        BLEU = brevity_panelty_val * modified_n_gram_precision\n",
        "\n",
        "        # intersection of pred and target to get correct prediction count\n",
        "        indices = torch.zeros_like(target_tensor_trimmed, dtype = torch.uint8, device = 'cuda')\n",
        "        for elem in predicted_target_trimmed:\n",
        "            indices = indices | (target_tensor_trimmed == elem)  \n",
        "        intersection = target_tensor_trimmed[indices]  \n",
        "        indices_backward = torch.zeros_like(predicted_target_trimmed, dtype = torch.uint8, device = 'cuda')\n",
        "        for elem in target_tensor_trimmed:\n",
        "            indices_backward = indices_backward | (predicted_target_trimmed == elem)  \n",
        "        intersection_backward = predicted_target_trimmed[indices_backward]\n",
        "\n",
        "        correct_predictions_count = min(intersection.shape[0], intersection_backward.shape[0])\n",
        "\n",
        "        # Generic Precision value and Recall value\n",
        "        total_predictions_count = predicted_target_trimmed.shape[0]\n",
        "        if total_predictions_count != 0:\n",
        "            precision = correct_predictions_count / total_predictions_count\n",
        "        else:\n",
        "            precision = 0\n",
        "        total_actual_count = target_tensor_trimmed.shape[0]\n",
        "        recall = correct_predictions_count / total_actual_count\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        predicted_target = torch.zeros(max_length, 1, device=device)  # evaluation\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "\n",
        "            prob_for_perplexity.append(topv.squeeze())\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            predicted_target[di] = decoder_input  # evaluation\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "        perplexity = math.exp((-1/target_length) * sum(prob_for_perplexity))\n",
        "\n",
        "        predicted_target_trimmed = predicted_target[predicted_target.sum(dim=1) != 0]  # remove unwanted rows at the end with 0 value.\n",
        "        predicted_target_trimmed = predicted_target_trimmed[predicted_target_trimmed[:, 0] !=1]  # remove last row in case it has EOS token\n",
        "        row_exclude = target_tensor.shape[0]-1\n",
        "        target_tensor_trimmed = torch.cat((target_tensor[:row_exclude],target_tensor[row_exclude+1:]))  # remove EOS token from end\n",
        "        # print('pred and target ', predicted_target_trimmed , target_tensor_trimmed)\n",
        "        # Calculate unigram precision for predicted and target. Continue to compute penalty and BLEU score.\n",
        "        unigram_precision_value = unigram_precision(predicted_target_trimmed, target_tensor_trimmed)\n",
        "        modified_n_gram_precision = math.sqrt(unigram_precision_value)  # n is 2 - square root - since we are using unigram and bigrams.\n",
        "        brevity_panelty_val = brevity_panelty(predicted_target_trimmed, target_tensor_trimmed)\n",
        "        # print(brevity_panelty_val, modified_n_gram_precision)\n",
        "        BLEU = brevity_panelty_val * modified_n_gram_precision\n",
        "        # print(unigram_precision_value, modified_n_gram_precision)\n",
        "        # intersection of pred and target to get correct prediction count\n",
        "        indices = torch.zeros_like(target_tensor_trimmed, dtype = torch.uint8, device = 'cuda')\n",
        "        for elem in predicted_target_trimmed:\n",
        "            indices = indices | (target_tensor_trimmed == elem)  \n",
        "        intersection = target_tensor_trimmed[indices]  \n",
        "        indices_backward = torch.zeros_like(predicted_target_trimmed, dtype = torch.uint8, device = 'cuda')\n",
        "        for elem in target_tensor_trimmed:\n",
        "            indices_backward = indices_backward | (predicted_target_trimmed == elem)  \n",
        "        intersection_backward = predicted_target_trimmed[indices_backward]\n",
        "\n",
        "        correct_predictions_count = min(intersection.shape[0], intersection_backward.shape[0])\n",
        "\n",
        "        # Generic Precision value and Recall value\n",
        "        total_predictions_count = predicted_target_trimmed.shape[0]\n",
        "        if total_predictions_count != 0:\n",
        "            precision = correct_predictions_count / total_predictions_count\n",
        "        else:\n",
        "            precision = 0\n",
        "\n",
        "        total_actual_count = target_tensor_trimmed.shape[0]\n",
        "        recall = correct_predictions_count / total_actual_count\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length, precision, recall, BLEU, perplexity"
      ],
      "metadata": {
        "id": "SquSfMg0c95e"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "    print_precision_total = 0  # Reset every plot_every\n",
        "    print_recall_total = 0  # Reset every plot_every\n",
        "    print_BLEU_total = 0  # Reset every plot_every\n",
        "    print_perplexity_total = 0 # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss, precision, recall, BLEU, perplexity = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "        print_precision_total += precision\n",
        "        print_recall_total += recall\n",
        "        print_BLEU_total += BLEU\n",
        "        print_perplexity_total += perplexity\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_precision_avg = print_precision_total / print_every\n",
        "            print_recall_avg = print_recall_total / print_every\n",
        "            print_BLEU_avg = print_BLEU_total / print_every\n",
        "            print_perplexity_avg = print_perplexity_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print_precision_total = 0\n",
        "            print_recall_total = 0\n",
        "            print_BLEU_total = 0\n",
        "            print_perplexity_total = 0\n",
        "            print('%s (%d %d%%) %.4f  Precision: %.4f  Recall: %.4f  F1: %.4f, BLEU: %.4f, Perplexity: %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg, print_precision_avg, print_recall_avg,\n",
        "                                         ((2*print_precision_avg*print_recall_avg)/(print_recall_avg+print_precision_avg)), print_BLEU_avg, print_perplexity_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "VJnSm6OkdEgU"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(question_details.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, answer_details.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "# Order of Performance Matrics - Precision, Recall, F1, BLEU, Perplexity\n",
        "# trainIters(encoder1, attn_decoder1, 55000, print_every=5000)\n",
        "trainIters(encoder1, attn_decoder1, 50, print_every=5)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485,
          "referenced_widgets": [
            "f0e725e883a647dbbbf59d4627ca149b",
            "9a0f9bb271c54664a6f90337020d2b57",
            "95f3483ee0a147d8bc111ecd97b8d2ed",
            "3ec578caa2c84af8a2dc7300ea1196fc",
            "2060c34260224ed3a1792c4b54a19448",
            "413005c86f8e453c8156682cbb911e95",
            "b036863994ac4aed87cbaf2ed9cbcc9d",
            "49cc3d0ef4e34393a02497a49ff7f0cb",
            "7f7b85331af2404bb27e3e1e1420aac5",
            "a0c203aa78ba4efe9d75cf674675f14f",
            "3ee825b28dc9455ead847d70c742b5dd"
          ]
        },
        "id": "iltrDacLdowW",
        "outputId": "7577e9fc-a816-4c09-eddc-6d3c9bf6d1a4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0e725e883a647dbbbf59d4627ca149b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-1d6e6c4146df>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Order of Performance Matrics - Precision, Recall, F1, BLEU, Perplexity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# trainIters(encoder1, attn_decoder1, 55000, print_every=5000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-62-41f4b9de0dae>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBLEU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-3426886f299d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mtarget_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mtarget_sentence_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mBERT_P\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBERT_R\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBERT_F1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_sentence_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sentence_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Calculate unigram precision for predicted and target. Continue to compute penalty and BLEU score.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/bert_score/score.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(cands, refs, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, lang, return_hash, rescale_with_baseline)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"calculating scores...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     all_preds = bert_cos_score_idf(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mrefs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/bert_score/utils.py\u001b[0m in \u001b[0;36mbert_cos_score_idf\u001b[0;34m(model, refs, hyps, tokenizer, idf_dict, verbose, batch_size, device, all_layers)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_start\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0msen_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         embs, masks, padded_idf = get_bert_embedding(\n\u001b[0m\u001b[1;32m    383\u001b[0m             \u001b[0msen_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/bert_score/utils.py\u001b[0m in \u001b[0;36mget_bert_embedding\u001b[0;34m(all_sens, model, tokenizer, idf_dict, batch_size, device, all_layers)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \"\"\"\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0mpadded_sens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_idf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollate_idf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_sens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/bert_score/utils.py\u001b[0m in \u001b[0;36mcollate_idf\u001b[0;34m(arr, tokenizer, idf_dict, device)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m'cpu'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \"\"\"\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msent_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0midf_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/bert_score/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m'cpu'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \"\"\"\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msent_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0midf_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/bert_score/utils.py\u001b[0m in \u001b[0;36msent_encode\u001b[0;34m(tokenizer, sent)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_prefix_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'RobertaTokenizerFast' object has no attribute 'max_len'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision - How many correct predictions were made out of total predictions made? - We check the number of words in prediction that are present in \n",
        "#  reference and divide it by total number of words in prediction. \n",
        "# Recall - How many correct predictions were made out of the total actuals? - We check the number of words in prediction that are present in \n",
        "#  reference and divide it by total number of words in actual.\n",
        "# F1 score - 2*precision*recall / (precision + recall)\n",
        "# BLEU Score  - Refer BLUE score PPT from Mtech NLP Lecture\n",
        "# Perplexity - Exponential of negative log likelihood."
      ],
      "metadata": {
        "id": "er38Xt7_BQYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "#     with torch.no_grad():\n",
        "#         input_tensor = tensorFromSentence(question_details, sentence)\n",
        "#         input_length = input_tensor.size()[0]\n",
        "#         encoder_hidden = encoder.initHidden()\n",
        "\n",
        "#         encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "#         for ei in range(input_length):\n",
        "#             encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "#                                                      encoder_hidden)\n",
        "#             encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "#         decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "#         decoder_hidden = encoder_hidden\n",
        "\n",
        "#         decoded_words = []\n",
        "#         decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "#         for di in range(max_length):\n",
        "#             decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "#                 decoder_input, decoder_hidden, encoder_outputs)\n",
        "#             decoder_attentions[di] = decoder_attention.data\n",
        "#             topv, topi = decoder_output.data.topk(1)\n",
        "#             if topi.item() == EOS_token:\n",
        "#                 decoded_words.append('<EOS>')\n",
        "#                 break\n",
        "#             else:\n",
        "#                 decoded_words.append(answer_details.index2word[topi.item()])\n",
        "\n",
        "#             decoder_input = topi.squeeze().detach()\n",
        "\n",
        "#         return decoded_words, decoder_attentions[:di + 1]\n",
        "\n",
        "# def evaluateRandomly(encoder, decoder, n=10):\n",
        "#     for i in range(n):\n",
        "#         pair = random.choice(pairs)\n",
        "#         print('>', pair[0])\n",
        "#         print('=', pair[1])\n",
        "#         output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "#         output_sentence = ' '.join(output_words)\n",
        "#         print('<', output_sentence)\n",
        "#         print('')\n",
        "\n",
        "# evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "metadata": {
        "id": "sOoiFnYxpcqi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}