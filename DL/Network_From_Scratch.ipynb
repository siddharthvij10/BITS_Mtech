{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b4fcb6fd",
      "metadata": {
        "id": "b4fcb6fd"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# make a input DF with 2 features/columns with normal distribution and make another df of expected output containing \n",
        "#   expected class as 97% and class not occuring at 3% - Binary Classification\n",
        "\n",
        "low = 0\n",
        "high = 1\n",
        "num_pop = 20\n",
        "\n",
        "feature_1_array = stats.truncnorm.rvs(low, high,\n",
        "                             loc = 0.5, scale = 0.1,\n",
        "                             size = num_pop)\n",
        "feature_2_array = stats.truncnorm.rvs(low, high,\n",
        "                             loc = 0.6, scale = 0.25,\n",
        "                             size = num_pop)\n",
        "data = {'x1': feature_1_array, 'x2': feature_2_array}\n",
        "input_data = pd.DataFrame(data = data)\n",
        "expected_output_data = [0, 1]  # [0.03, 0.97]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "49de6e0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "49de6e0e",
        "outputId": "057f8bb8-bc43-46aa-e756-d7d80a6408e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7281858225800159, 0.6480345311580447, 0.6089513080888024, 0.572901358194702, 0.5394483485018825, 0.5084273070748717, 0.479306649491988, 0.45239691162118356]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Binary Classification Use Case\n",
        "# 2 input features, 1 hidden layer with 2 nodes, 2 nodes in output layer\n",
        "# Activation of sigmoid in all layers except the output layer. Output layer to have softmax\n",
        "# Reference - The error gradient and FP equations used in this program are derived using pen and paper and the PDF for same is uploaded on slide share link \n",
        "#   mentioned here - https://www.slideshare.net/SiddharthVij4/networkfromscratchequationscomputation\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from math import log\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 4\n",
        "learning_rate = 0.35\n",
        "# we are implementing mini batch gradient descent here\n",
        "\n",
        "\n",
        "class network_from_scratch:\n",
        "    def __init__(self, ip_data, expected_output_data):\n",
        "        self.input_data = input_data\n",
        "        self.expected_output_data = expected_output_data\n",
        "        initial_weights_vector = self.initialize_wt()\n",
        "        weights_vector = len(initial_weights_vector) * [0]\n",
        "        count = 0\n",
        "        \n",
        "        def update_weights(gradients, weights):\n",
        "            return (weights-learning_rate*gradients)\n",
        "        \n",
        "        error_store = []\n",
        "        for epoch_no in range(0, epochs):  # epoch\n",
        "            for batch_no in range(0, self.input_data.shape[0], batch_size):  # batch\n",
        "                self.input_data_batch = self.input_data.iloc[batch_no: batch_no+batch_size]\n",
        "                gradient_vector = np.zeros([batch_size, len(initial_weights_vector)])\n",
        "                error_vector = np.zeros([batch_size])\n",
        "                for sample_no in range(0, batch_size):  # sample\n",
        "                    input_data_sample = self.input_data_batch.iloc[sample_no].to_list()\n",
        "                    if count == 0:\n",
        "                        gradient_vector[sample_no], error_vector[sample_no] = \\\n",
        "                        (self.fpbp(input_data_sample, initial_weights_vector))  # returned gradients are added\n",
        "                        count = 1\n",
        "                    else:\n",
        "                        gradient_vector[sample_no], error_vector[sample_no] = \\\n",
        "                        (self.fpbp(input_data_sample, weights_vector))  # returned gradients are added\n",
        "                        \n",
        "                gradient_vector_avg = gradient_vector.mean(axis=0)  # gradients are averaged after a batch is over.\n",
        "                weights_vector = update_weights(gradient_vector_avg, weights_vector)  # weights updated after batch is over\n",
        "                error = error_vector.mean()  # error for a batch is computed\n",
        "                error_store.append(error)\n",
        "                \n",
        "        print(error_store)\n",
        "        self.create_line_chart(error_store)\n",
        "        \n",
        "        \n",
        "    def create_line_chart(self, data_for_y_axis):\n",
        "        # data to be plotted\n",
        "        x = [i for i in range(0, int(epochs*(num_pop/batch_size)))]\n",
        "        x = np.array(x)\n",
        "        y = np.array(data_for_y_axis)\n",
        "\n",
        "        # plotting\n",
        "        plt.title(\"Line graph\")\n",
        "        plt.xlabel(\"Batch Number\")\n",
        "        plt.ylabel(\"Error\")\n",
        "        plt.plot(x, y, color =\"red\", label='line with marker', linestyle='--', marker='o')\n",
        "        plt.show()\n",
        "    \n",
        "    def compute_binary_cross_entropy_error(self, y1_pred):  # also called as log loss\n",
        "        log_loss = -(self.expected_output_data[0] * log(y1_pred)) -((1-self.expected_output_data[0])*log(1-y1_pred))\n",
        "        return log_loss\n",
        "\n",
        "    def apply_activation_sigmoid(self, z):  \n",
        "        sigma_activated_output = 1/(1+np.exp(-z))\n",
        "        return sigma_activated_output\n",
        "\n",
        "    def apply_activation_softmax(self, z_vector):   \n",
        "        denominator = 0\n",
        "        for i in z_vector:\n",
        "            denominator += np.exp(i)\n",
        "        \n",
        "        for i in range(0, len(z_vector)):\n",
        "            z_vector[i] = np.exp(z_vector[i])/denominator\n",
        "        \n",
        "        softmax_activated_output = z_vector\n",
        "        return softmax_activated_output    \n",
        "    \n",
        "    def initialize_wt(self):\n",
        "        return [np.random.sample(), np.random.sample(), np.random.sample(), np.random.sample(),\n",
        "                np.random.sample(), np.random.sample(), np.random.sample(), np.random.sample()]\n",
        "        \n",
        "    def fpbp(self, sample, weights_vector):  # z_2_1 means it belongs to layer 2 and node 1\n",
        "        z_2_1 = (weights_vector[0] * sample[0]) + (weights_vector[1] * sample[1])\n",
        "        a_2_1 = self.apply_activation_sigmoid(z_2_1)\n",
        "        z_2_2 = (weights_vector[2] * sample[0]) + (weights_vector[3] * sample[1])\n",
        "        a_2_2 = self.apply_activation_sigmoid(z_2_2)\n",
        "\n",
        "        z_3_1 = (weights_vector[4] * a_2_1) + (weights_vector[5] * a_2_2)\n",
        "        z_3_2 = (weights_vector[6] * a_2_1) + (weights_vector[7] * a_2_2)\n",
        "        a_3 = self.apply_activation_softmax([z_3_1, z_3_2])\n",
        "        a_3_1, a_3_2 = a_3[0], a_3[1]\n",
        "\n",
        "        y1_pred = a_3_1\n",
        "        y2_pred = a_3_2\n",
        "        \n",
        "        # Concept required for backpropagation - log loss error which only needs y1_pred and not y2_pred is made of 2 components which are -y1logy1_pred \n",
        "        #   and -(1-y1)log(1-y1_pred). The second component can also be written as -y2log(y2). These 2 components can be \n",
        "        #   e1 and e2 which both add up to make e\n",
        "        e = self.compute_binary_cross_entropy_error(y1_pred)\n",
        "        \n",
        "        # compute gradient of error w.r.t weights\n",
        "        # The derivation of gradient formulas is done with pen and paper. A screenshot of same is attached below for ref.\n",
        "        grad_e_w5 = (-expected_output_data[0] * (1-y1_pred) * a_2_1)\n",
        "        grad_e_w6 = (-expected_output_data[0] * (1-y1_pred) * a_2_2)\n",
        "        grad_e_w7 = (-expected_output_data[1] * (1-y2_pred) * a_2_1)\n",
        "        grad_e_w8 = (-expected_output_data[1] * (1-y2_pred) * a_2_2)\n",
        "        grad_e_w1 = (a_2_1 * (1-a_2_1) * sample[0]) * \\\n",
        "                    ((-expected_output_data[0] * (1-y1_pred) * weights_vector[4]) \n",
        "                     + (-expected_output_data[1] * (1-y2_pred) * weights_vector[6]))\n",
        "        grad_e_w2 = (a_2_1 * (1-a_2_1) * sample[1]) * \\\n",
        "                    ((-expected_output_data[0] * (1-y1_pred) * weights_vector[4]) \n",
        "                     + (-expected_output_data[1] * (1-y2_pred) * weights_vector[6]))\n",
        "        grad_e_w3 = (a_2_2 * (1-a_2_2) * sample[0]) * \\\n",
        "                    ((-expected_output_data[1] * (1-y2_pred) * weights_vector[7]) \n",
        "                     + (-expected_output_data[0] * (1-y1_pred) * weights_vector[5]))\n",
        "        grad_e_w4 = (a_2_2 * (1-a_2_2) * sample[1]) * \\\n",
        "                    ((-expected_output_data[1] * (1-y2_pred) * weights_vector[7]) \n",
        "                     + (-expected_output_data[0] * (1-y1_pred) * weights_vector[5]))\n",
        "        grad_vector_for_sample = [grad_e_w1, grad_e_w2, grad_e_w3, grad_e_w4, grad_e_w5, grad_e_w6, grad_e_w7, grad_e_w8]\n",
        "        return grad_vector_for_sample, e\n",
        "    \n",
        "nw = network_from_scratch(input_data, expected_output_data)\n",
        "\n",
        "# insights - \n",
        "# 1- binary cross entropy error or log loss penalizes values which are far from expected. \n",
        "# 2- softmax converts output predictions into relative preditions in such a way that both predictions add up to 1."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}