{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMROPVj2RyuiPNzMmYn+S1o"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63b59d1e27744a468f5d65035ee5fe4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13d2ba35d0de4cedabc9940f14ffc8f4",
              "IPY_MODEL_c5458b10792040ea83170b614cbf5d79",
              "IPY_MODEL_75296e6491c344479f4e6821bc34996a"
            ],
            "layout": "IPY_MODEL_e79097249edd4e50830adbcdf53714fe"
          }
        },
        "13d2ba35d0de4cedabc9940f14ffc8f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47a6f16abccb4411898bbbc8e340e675",
            "placeholder": "​",
            "style": "IPY_MODEL_c942feb301f24cb893f62e4f5cca4b30",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c5458b10792040ea83170b614cbf5d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_218ae535893a47f18d17f23caa2d6633",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dbc99429f8a47e8aa7a5da456c63cb9",
            "value": 8
          }
        },
        "75296e6491c344479f4e6821bc34996a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4a96712c63d4db0b17a470dfec11a10",
            "placeholder": "​",
            "style": "IPY_MODEL_2c512774fc5e413492384d4dfe4c41d4",
            "value": " 8/8 [01:09&lt;00:00,  7.38s/it]"
          }
        },
        "e79097249edd4e50830adbcdf53714fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47a6f16abccb4411898bbbc8e340e675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c942feb301f24cb893f62e4f5cca4b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "218ae535893a47f18d17f23caa2d6633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dbc99429f8a47e8aa7a5da456c63cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4a96712c63d4db0b17a470dfec11a10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c512774fc5e413492384d4dfe4c41d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIa_KZwcm46u",
        "outputId": "a5b66abd-0f8e-42ed-d251-116aa0bb48a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y tensorflow --quiet\n",
        "!pip install git+https://github.com/ludwig-ai/ludwig.git@master --quiet\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "import locale\n",
        "\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = getpass.getpass(\"Token:\")\n",
        "assert os.environ[\"HUGGING_FACE_HUB_TOKEN\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4PZQM1-swWd",
        "outputId": "8fe5628e-5842-4a30-ccf3-56f2afe2258a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Load Sharded Model\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "  pretrained_model_name_or_path=\"Siddharthvij10/MistralSharded2\",\n",
        "  trust_remote_code=True,\n",
        "  padding_side=\"left\"\n",
        ")\n",
        "\n",
        "bnb_config_4bit = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    load_in_8bit=False,\n",
        "    llm_int8_threshold=6.0,\n",
        "    llm_int8_has_fp16_weight=False,\n",
        "    bnb_4bit_compute_dtype=\"float16\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "  pretrained_model_name_or_path=\"Siddharthvij10/MistralSharded2\",\n",
        "  device_map=\"auto\",\n",
        "  torch_dtype=torch.float16,\n",
        "  offload_folder=\"offload\",\n",
        "  trust_remote_code=True,\n",
        "  low_cpu_mem_usage=True,\n",
        "  quantization_config=bnb_config_4bit\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "63b59d1e27744a468f5d65035ee5fe4b",
            "13d2ba35d0de4cedabc9940f14ffc8f4",
            "c5458b10792040ea83170b614cbf5d79",
            "75296e6491c344479f4e6821bc34996a",
            "e79097249edd4e50830adbcdf53714fe",
            "47a6f16abccb4411898bbbc8e340e675",
            "c942feb301f24cb893f62e4f5cca4b30",
            "218ae535893a47f18d17f23caa2d6633",
            "5dbc99429f8a47e8aa7a5da456c63cb9",
            "e4a96712c63d4db0b17a470dfec11a10",
            "2c512774fc5e413492384d4dfe4c41d4"
          ]
        },
        "id": "GypGT1c9syiH",
        "outputId": "22a1442f-fb3e-4942-ad31-94aa4f8802dc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63b59d1e27744a468f5d65035ee5fe4b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Inference on loaded model\n",
        "\n",
        "def inference(instruction, input):\n",
        "\n",
        "  test_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that may provide further context. Write a response that appropriately completes the request.\n",
        "  ### Instruction: {}\n",
        "  ### Input: {}\n",
        "  ### Response:\"\"\".format(instruction, input)\n",
        "\n",
        "  sequences_generator = transformers.pipeline(\n",
        "    task=\"text-generation\",\n",
        "    tokenizer=tokenizer,\n",
        "    model=base_model,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        "  )\n",
        "\n",
        "\n",
        "  sequences: list[dict] | list[list[dict]] = sequences_generator(\n",
        "    text_inputs=test_prompt,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    max_length=512,\n",
        "    return_text=True,\n",
        "  )\n",
        "\n",
        "  sequence: dict = sequences[0]\n",
        "  print(sequence[\"generated_text\"])\n",
        "  print(\"\\n\\n---------------------------------------------\")\n",
        "  return sequence[\"generated_text\"]"
      ],
      "metadata": {
        "id": "aJa84XUHs2IL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Import dataset and run inference on 5 data points from code alpeca dataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json(\"https://raw.githubusercontent.com/sahil280114/codealpaca/master/data/code_alpaca_20k.json\")\n",
        "df = df.head(n=5)\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    generation = inference(row['instruction'], row['input'])\n",
        "    df.loc[df.index[index], 'generation'] = generation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L-RN9pGzEmv",
        "outputId": "33167524-f218-486d-c642-5f3e2f93c1d4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task, paired with an input that may provide further context. Write a response that appropriately completes the request.\n",
            "  ### Instruction: Create an array of length 5 which contains all even numbers between 1 and 10.\n",
            "  ### Input: \n",
            "  ### Response: `var arr = []; for (var i = 2; i <= 10; i = i + 2) { arr.push(i); }`\n",
            " \n",
            "## Explanation:\n",
            "\n",
            "The `Create` instruction describes a task, which in this case is to create an array of length 5 that contains all even numbers between 1 and 10. The `Input` section provides a context for the task in the form of a block of code. This code block contains a function that creates an integer array that starts at 2 and increments by 2. When this array is pushed onto the `arr` variable, that array will be the appropriate response to complete the `Create` instruction. \n",
            "\n",
            "[Back to home](https://warm-wave-85838.herokuapp.com/guide)\n",
            "\n",
            "\n",
            "---------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task, paired with an input that may provide further context. Write a response that appropriately completes the request.\n",
            "  ### Instruction: Formulate an equation to calculate the height of a triangle given the angle, side lengths and opposite side length.\n",
            "  ### Input: \n",
            "  ### Response: To calculate the height of a triangle given the angle, side lengths, and opposite side length, we can use the sine function. The equation to calculate the height is:\n",
            "\n",
            "\n",
            "\n",
            "<small>\n",
            "\n",
            "  <p><b>References</b></p>\n",
            "  <ul><li>Hugging Face:</li></ul>\n",
            "  <ul><li>Model Name: <a href=\"https://huggingface.co/docs/models/llama\">LLaMA</a></li></ul>\n",
            "  <ul><li>Model Architecture: <a href=\"https://huggingface.co/docs/models/llama_7b_hf\">llama-7b-hf</a></li></ul>\n",
            "  <ul><li>Dataset: <a href=\"https://huggingface.co/docs/datasets/chatbot\">ChatBot</a></li></ul>\n",
            "  <ul><li>Prompt Design: <a href=\"https://huggingface.co/junyanzhen/chatgpt-instruction-design-chatbot\">junyanzhen/chatgpt-instruction-design-chatbot</a></li></ul>\n",
            "  <ul><li>Model Fine-tuning/Re-training:</li></ul>\n",
            "  <ul><li>Fine-tuning Method: <a href=\"https://huggingface.co/docs/models/fine_tuning\">Fine-tuning</a></li></ul>\n",
            "  <ul><li>Fine-tuning Architecture: <a href=\"https://huggingface.co/docs/models/fine_tuning_hf\">Fine-tuning (hf)</a></li></ul>\n",
            "\n",
            "</small>\n",
            "\n",
            "\n",
            "---------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task, paired with an input that may provide further context. Write a response that appropriately completes the request.\n",
            "  ### Instruction: Write a replace method for a string class which replaces the given string with a given set of characters.\n",
            "  ### Input: string = \"Hello World!\"\n",
            "replace_with = \"Greetings!\"\n",
            "  ### Response: We created a method called replace which takes in two arguments, string and replace_with. The method returns a given sentence with'replace_with' replacing every word in the string that has a length greater than 4 chars.\n",
            "  def replace(string, replace_with)\n",
            "    string.split.map {|word| replace_with if word.length>4 else word}.join(\" \")\n",
            "  end\n",
            "\n",
            "end\n",
            "\n",
            "  # Create a method that returns the highest value within an array of integers\n",
            "  def find_max(input)\n",
            "    input.max\n",
            "  end\n",
            "\n",
            "\n",
            "  # Create a method that returns true if a substring is contained within a larger string\n",
            "  def substring?(input, string_to_search)\n",
            "  input.include?(string_to_search)\n",
            "  end\n",
            "\n",
            "  # Create a method that returns an array containing an even number of the same element\n",
            "\n",
            "  # Given a string, return a new string where the first and last chars have been exchanged.\n",
            "  # def swap(input)\n",
            "  #   input.split.map {|word| word[0,1]}.join\n",
            "  # end\n",
            "\n",
            "\n",
            "  # Create a method that returns true if \"no\" is a part of a longer string\n",
            "  def end_no(input)\n",
            "    input.include?(\"no\") && input.count(\"no\") ==1? true : false\n",
            "  end\n",
            "\n",
            "  # Create a method that will reverse the order of characters in a string.\n",
            "  # def reverse(input)\n",
            "  #   input.split.reverse.join\n",
            "  # end\n",
            "\n",
            "  # Given two strings, create a method that will return true if one is a rotation of the other (meaning you can get one from the other by \"rotating\" it in place, such as \"rota\" being a rotation of \"ator\")\n",
            "  # def rotation(input1,input2)\n",
            "  #   rotation = input2.split.slice(\n",
            "\n",
            "\n",
            "---------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task, paired with an input that may provide further context. Write a response that appropriately completes the request.\n",
            "  ### Instruction: Create an array of length 15 containing numbers divisible by 3 up to 45.\n",
            "  ### Input: \n",
            "  ### Response: In this example, the response is:\n",
            "    [15, 18, 21, 24, 27, 30, 33, 36, 45],\n",
            "  ####  <a href=\"#input\" style=\"vertical-align:top;font-size:14px;\">Top of Input - Click to Return</a>\n",
            "\n",
            "---\n",
            "### Input:\n",
            "```javascript\n",
            "/**\n",
            " * Create an array of length 15 containing numbers divisible by 3 up to 45.\n",
            " */\n",
            "```\n",
            "\n",
            "---\n",
            "### Response:\n",
            "```javascript\n",
            "\n",
            "```\n",
            "## 1.10.6: Write a `sumWith()` function\n",
            "###### [Source code](https://github.com/jb-hilton/js-1-2/blob/main/src/1.10.sum-with.js)\n",
            "\n",
            "    [ ]\n",
            "#### Description:\n",
            "\n",
            "### 1.10.6: Write a `sumWith()` function\n",
            "\n",
            "Write a JavaScript function that takes in an array and a callback function as inputs, and returns the sum of the array, with each element of the array passed to the callback function.\n",
            "\n",
            "Here is an example of the function in action:\n",
            "\n",
            "#### Example:\n",
            "```javascript\n",
            "/**\n",
            " * sum an array, with each item passed to the given callback\n",
            " */\n",
            "// function sumWith(arr, cb) {\n",
            "//   //...\n",
            "// }\n",
            "//\n",
            "// // example inputs\n",
            "const callback = x => {\n",
            "  return x + 3;\n",
            "};\n",
            "const nums = [1,2,3];\n",
            "// example output - add the elements of nums, and 3 to each result\n",
            "console.log(sumWith(nums, callback)); // 12\n",
            "```\n",
            "####  <a href=\"#input\" style=\"vertical-align:top;font-size:14px;\">Top of Input - Click to Return</a>\n",
            "\n",
            "---\n",
            "### Input:\n",
            "```\n",
            "\n",
            "\n",
            "---------------------------------------------\n",
            "Below is an instruction that describes a task, paired with an input that may provide further context. Write a response that appropriately completes the request.\n",
            "  ### Instruction: Write a function to find the number of distinct states in a given matrix.\n",
            "  ### Input: matrix = [[1, 0, 0],\n",
            "          [1, 0, 1],\n",
            "          [1, 1, 1]]\n",
            "  ### Response: 2\n",
            "\n",
            "  test_input = \"[3,18]\"\n",
            "  for i in reversed(range(5)):\n",
            "    if test_input[i] == '[':\n",
            "      break\n",
            "  print(test_input[i+1:])\n",
            "\n",
            "#test = input.split()\n",
            "#numbers : [2, 45,6,59]\n",
            "\n",
            "def get_result(instruction,test_input ):\n",
            "  '''\n",
            "  given an input instruction and an input text, the function get_result will return\n",
            "  the response with a corresponding instruction or the corresponding test_input. The function will also take\n",
            "  an optional dictionary input.\n",
            "\n",
            "  Parameters\n",
            "  -----------------------\n",
            "  instruction  : str\n",
            "    The instruction string. E.g, \"Write a function to find the number of unique numbers in a given sorted array\".\n",
            "  input: str\n",
            "    The input text. E.g, \"nums = [1,2,3,4,5]\".\n",
            "\n",
            "  Returns\n",
            "  -----------\n",
            "  response: str\n",
            "    The response text. E.g, \"2\".\n",
            "\n",
            "  '''\n",
            "  print(f\"Here is the instruction: ({instruction})\")\n",
            "  print(f\"Here is the input: (test_input)\")\n",
            "  response=instruction+f\"\\n {test_input}\"\n",
            "  print(f\"And here is the response: ({response})\")\n",
            "\n",
            "def check_response(response, expected_response):\n",
            "  '''\n",
            "  The function takes an response string and an expected_response string as input. Each string\n",
            "  is tested to see if it corresponds to the instruction.\n",
            "\n",
            "  Parameters\n",
            "  -----------\n",
            "  response: str\n",
            "    This is the response string that the user entered.\n",
            "  expected_response: str\n",
            "    This is the expected response string.\n",
            "\n",
            "  Returns\n",
            "  ---------------\n",
            "  bool\n",
            "    True if the response is the\n",
            "\n",
            "\n",
            "---------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}