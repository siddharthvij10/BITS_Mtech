{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIiBv0y4vUqgVZHbQuH8iv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip uninstall -y tensorflow\n",
        "! pip install -q tf-nightly  # Use tf-nightly instead of tensorflow since it gets updated with fixes every day\n",
        "! pip install -q tensorflow-model-optimization  # this lib is used for QAT\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwxFIa8W_PGZ",
        "outputId": "0fd33989-d2a8-4587-e397-ff49b8ee84cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.15.0\n",
            "Uninstalling tensorflow-2.15.0:\n",
            "  Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.0/590.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Sample Keras model - Code generated by ChatGPT\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(0)\n",
        "data = pd.DataFrame(np.random.rand(1000, 5), columns=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5'])\n",
        "target = pd.Series(np.random.randint(0, 2, size=1000), name='Target')\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the Keras model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(5,)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGuqPPDG_Jqc",
        "outputId": "52645332-e86f-4468-8b4b-749cd442bdb8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - 29s 29ms/step - loss: 0.6988 - accuracy: 0.4906 - val_loss: 0.6926 - val_accuracy: 0.5250\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5453 - val_loss: 0.6908 - val_accuracy: 0.4812\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5469 - val_loss: 0.6890 - val_accuracy: 0.4875\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6836 - accuracy: 0.5469 - val_loss: 0.6925 - val_accuracy: 0.5375\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6814 - accuracy: 0.5688 - val_loss: 0.6914 - val_accuracy: 0.5375\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.5719 - val_loss: 0.6919 - val_accuracy: 0.5375\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6784 - accuracy: 0.5656 - val_loss: 0.6924 - val_accuracy: 0.5500\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.5734 - val_loss: 0.6893 - val_accuracy: 0.5625\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.5781 - val_loss: 0.6923 - val_accuracy: 0.5437\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.5813 - val_loss: 0.6907 - val_accuracy: 0.5562\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.5850\n",
            "Test Loss: 0.6908831596374512, Test Accuracy: 0.5849999785423279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnEsepzG_EJ9",
        "outputId": "68e2c2e1-c663-4da5-aded-557e27fc3793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - 4s 58ms/step - loss: 0.6740 - accuracy: 0.5703 - val_loss: 0.6916 - val_accuracy: 0.5437\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6701 - accuracy: 0.5750 - val_loss: 0.6901 - val_accuracy: 0.5250\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.6681 - accuracy: 0.5891 - val_loss: 0.6945 - val_accuracy: 0.5250\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.6660 - accuracy: 0.5969 - val_loss: 0.6917 - val_accuracy: 0.5437\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 1s 41ms/step - loss: 0.6643 - accuracy: 0.5859 - val_loss: 0.6911 - val_accuracy: 0.5500\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6634 - accuracy: 0.6016 - val_loss: 0.6934 - val_accuracy: 0.5312\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6612 - accuracy: 0.5984 - val_loss: 0.6940 - val_accuracy: 0.5375\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6605 - accuracy: 0.6047 - val_loss: 0.6934 - val_accuracy: 0.5312\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6598 - accuracy: 0.5953 - val_loss: 0.6922 - val_accuracy: 0.5437\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6586 - accuracy: 0.6062 - val_loss: 0.6928 - val_accuracy: 0.5500\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 0.6963 - accuracy: 0.5400\n",
            "Test Loss: 0.6962602138519287, Test Accuracy: 0.5400000214576721\n"
          ]
        }
      ],
      "source": [
        "quant_aware_model = tfmot.quantization.keras.quantize_model(model)\n",
        "quant_aware_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fine tune to create a quant aware model\n",
        "quant_aware_model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the quant aware model\n",
        "test_loss, test_accuracy = quant_aware_model.evaluate(X_test_scaled, y_test)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
      ]
    }
  ]
}